{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "En toda esta sección se entrenarán redes neuronales de 1 sola capa oculta entrenando\n",
        "con gradiente descendente clásico. Se buscará apreciar las bondades de una red como\n",
        "aproximador universal (no nos importa por ahora la capacidad de generalización).\n",
        "\n"
      ],
      "metadata": {
        "id": "ElmQpqPwtxTC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Clasificación"
      ],
      "metadata": {
        "id": "PIxz8Ye9t0EB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Generar una base de datos de una XOR con todas las posibles combinaciones de\n",
        "±1 (4 casos). Asignar los labels correspondientes (1 si ambas entradas son iguales,\n",
        "0 si son diferentes)."
      ],
      "metadata": {
        "id": "dHxtsNi0t2FY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEHtwpqDtiTN",
        "outputId": "45eaf74f-1748-45c9-bef3-e4f4dafb11d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 2)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Pongo -1 en vez de 0 para que la RELU pueda trabajar bien\n",
        "datos = [[-1, -1, 0],\n",
        "          [-1, 1, 1],\n",
        "          [1, -1, 1],\n",
        "         [1,1,0]]\n",
        "\n",
        "columnas = ['Bit 1', 'Bit 2', 'Output'] \n",
        "\n",
        "df = pd.DataFrame(datos, columns=columnas)\n",
        "df.head()\n",
        "\n",
        "training_data = df.loc[:,['Bit 1','Bit 2']]\n",
        "target_data = df.loc[:,'Output']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Entrenar una red neuronal con activación ReLU que alcance 100 % de accuracy. ¿Cuál es la mínima dimensión de la unidad oculta para lograr esto?"
      ],
      "metadata": {
        "id": "50gYj0mtwRLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "import tensorflow as tf\n",
        "\n",
        "# Creo la arquitectura de la red neuronal\n",
        "model = Sequential()                                          # Secuencial -> creo una serie de capas de neuronas secuenciales, una delante de otra.\n",
        "model.add(Dense(8, input_dim=2, activation='relu'))          # input_dim = 2 (defino la capa de entrada con 2 neuronas, BIT0 y BIT1 de XOR)\n",
        "model.add(Dense(1))                                           # La dimensión de la capa oculta es el primer parámetro\n",
        "                                                              # Por último agregamos una capa de salida (en este caso sin funcion de activacion xq estamos en clasificacion)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhDz6AkXyAfj",
        "outputId": "220f4dee-b3ab-45c5-dda6-d30196d7ef45"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_60 (Dense)            (None, 8)                 24        \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33\n",
            "Trainable params: 33\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=1)\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=10), loss = tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
        "model.fit(training_data, target_data, epochs=100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0hIGXDSzhnE",
        "outputId": "b6766ffa-0b17-416f-bd91-6196d0cc4347"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 871ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.8309e-04 - accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.4744e-04 - accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.0257e-04 - accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.6556e-04 - accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.2815e-04 - accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.9930e-04 - accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.6969e-04 - accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.4001e-04 - accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1528e-04 - accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9038e-04 - accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7099e-04 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.4689e-04 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.2817e-04 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.0767e-04 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.9087e-04 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.7394e-04 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.5726e-04 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.4279e-04 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2761e-04 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.1403e-04 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.0091e-04 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.8848e-04 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.7590e-04 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.6501e-04 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.5429e-04 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.4342e-04 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.3329e-04 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.2390e-04 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.1488e-04 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.0563e-04 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9718e-04 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8917e-04 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8124e-04 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7342e-04 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6621e-04 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6010e-04 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.5210e-04 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.4589e-04 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.3934e-04 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.3324e-04 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2712e-04 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2214e-04 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1689e-04 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1064e-04 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0627e-04 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0108e-04 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9572e-04 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9157e-04 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8679e-04 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8216e-04 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7780e-04 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7387e-04 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6954e-04 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6580e-04 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6187e-04 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5793e-04 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5432e-04 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5089e-04 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4739e-04 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4385e-04 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4069e-04 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3750e-04 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3413e-04 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3127e-04 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2851e-04 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2517e-04 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2232e-04 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1965e-04 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1713e-04 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1410e-04 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1166e-04 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0933e-04 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0652e-04 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0415e-04 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0205e-04 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9973e-04 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9713e-04 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9533e-04 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9310e-04 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9071e-04 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8886e-04 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8673e-04 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdbd15bfd10>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La mínima dimensión de la unidad oculta para lograr esto es de 8 (fui probando)"
      ],
      "metadata": {
        "id": "STGL9GO92F7C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Repetir con activación sigmoide. Extraer conclusiones."
      ],
      "metadata": {
        "id": "L5_cL0Bs2Mcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creo la arquitectura de la red neuronal\n",
        "model = Sequential()                                          \n",
        "model.add(Dense(2, input_dim=2, activation='sigmoid'))         \n",
        "model.add(Dense(1))                     \n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCyWhGfw2QpB",
        "outputId": "b7650890-bf85-4141-9fa9-6ae9cfa1f013"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_56 (Dense)            (None, 2)                 6         \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9\n",
            "Trainable params: 9\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=1)\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1), loss = tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
        "model.fit(training_data, target_data, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BwmsEwR3SKR",
        "outputId": "d48bbd75-f848-4004-c387-4be69a58ee9d"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 358ms/step - loss: 5.3450e-05 - accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.3424e-05 - accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3402e-05 - accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3383e-05 - accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.3362e-05 - accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.3342e-05 - accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3325e-05 - accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3305e-05 - accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3285e-05 - accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3266e-05 - accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3249e-05 - accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3228e-05 - accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.3209e-05 - accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.3191e-05 - accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3171e-05 - accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.3154e-05 - accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3134e-05 - accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3115e-05 - accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.3097e-05 - accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.3078e-05 - accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.3060e-05 - accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.3040e-05 - accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.3022e-05 - accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 5.3003e-05 - accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983e-05 - accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2966e-05 - accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2947e-05 - accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2927e-05 - accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2909e-05 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2890e-05 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.2871e-05 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2852e-05 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2834e-05 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2815e-05 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2796e-05 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2778e-05 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.2759e-05 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2742e-05 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2722e-05 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2703e-05 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.2686e-05 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2667e-05 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2647e-05 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2628e-05 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2611e-05 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2591e-05 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2575e-05 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2555e-05 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2536e-05 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2519e-05 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2501e-05 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2481e-05 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.2463e-05 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2445e-05 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2426e-05 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2407e-05 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2390e-05 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.2371e-05 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.2352e-05 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.2334e-05 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2316e-05 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2297e-05 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2280e-05 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2261e-05 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2243e-05 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2224e-05 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2205e-05 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2187e-05 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2170e-05 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2150e-05 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.2132e-05 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2116e-05 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2096e-05 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.2078e-05 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2060e-05 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.2042e-05 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2024e-05 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2006e-05 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1988e-05 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.1969e-05 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1952e-05 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1934e-05 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1914e-05 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1898e-05 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.1880e-05 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1860e-05 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.1843e-05 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.1825e-05 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1807e-05 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.1788e-05 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1771e-05 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1753e-05 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1735e-05 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1717e-05 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1699e-05 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1682e-05 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1663e-05 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1646e-05 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.1628e-05 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.1610e-05 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdbcdd70fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede ver que ahora la mínima dimensión de la unidad oculta para lograr esto es de 2, usando 1 en learning rate"
      ],
      "metadata": {
        "id": "67Jt3cHp3f9X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Regresión"
      ],
      "metadata": {
        "id": "v1xL1G7U8uyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generar una base de datos de la función f(x, y, z) = sin(x) + cos(y) + z. Para ello\n",
        "barra una grilla de 20 puntos para cada coordenada (0 ≤ x < 2π, 0 ≤ y < 2π y\n",
        "0 ≤ z ≤ 1) y arme una base de datos con las 8000 combinaciones posibles."
      ],
      "metadata": {
        "id": "duyVatfK8x1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import itertools as it\n",
        "import numpy as np\n",
        "\n",
        "def f(x, y, z):\n",
        "  return math.sin(x) + math.cos(x) + z\n",
        "\n",
        "x_step = (2 * math.pi) / 20\n",
        "y_step = (2 * math.pi) / 20\n",
        "z_step = 1 / 20\n",
        "\n",
        "x_points, y_points, z_points = [], [], []\n",
        "for i in range(20): x_points.append(x_step * i)\n",
        "for i in range(20): y_points.append(y_step * i)\n",
        "for i in range(20): z_points.append(z_step * i)\n",
        "\n",
        "combinations = it.product(x_points, y_points)\n",
        "combinations = it.product(combinations, z_points)\n",
        "training_data = np.array([[x, y, z] for (x, y), z in combinations]) # Si quiero convertir un iterador a lista usar list(iterator)\n",
        "target_data = np.array([f(x, y, z) for x, y, z in training_data])"
      ],
      "metadata": {
        "id": "eBPPKrjC9rUz"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenar una red neuronal con activación ReLU e indique el error cuadrático medio. Grafique f(x, x, x) y comparela con la salida del regresor barriendo x."
      ],
      "metadata": {
        "id": "Quh7UoPsBY_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()                                          \n",
        "model.add(Dense(64, input_dim=3, activation='relu'))         \n",
        "model.add(Dense(1))  \n",
        "\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=1)\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), loss = 'MeanSquaredError', metrics=[\"accuracy\"])\n",
        "model.fit(training_data, target_data, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uI0l6qYDBfoP",
        "outputId": "14cdfad1-8f11-4b53-8831-4d1927d4a637"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 1s 1ms/step - loss: 0.6949 - accuracy: 0.0033\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.5475 - accuracy: 0.0035\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.5080 - accuracy: 0.0034\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.0036\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4002 - accuracy: 0.0035\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3476 - accuracy: 0.0036\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2855 - accuracy: 0.0034\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2275 - accuracy: 0.0039\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.0039\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.1493 - accuracy: 0.0041\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.0041\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0960 - accuracy: 0.0041\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0796 - accuracy: 0.0044\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0645 - accuracy: 0.0044\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0511 - accuracy: 0.0045\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0431 - accuracy: 0.0046\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0400 - accuracy: 0.0049\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0316 - accuracy: 0.0047\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0241 - accuracy: 0.0050\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 0.0050\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0188 - accuracy: 0.0050\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0164 - accuracy: 0.0050\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0134 - accuracy: 0.0050\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0116 - accuracy: 0.0050\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0116 - accuracy: 0.0050\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0094 - accuracy: 0.0050\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0078 - accuracy: 0.0050\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0070 - accuracy: 0.0050\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0065 - accuracy: 0.0050\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0083 - accuracy: 0.0050\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0053 - accuracy: 0.0050\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0068 - accuracy: 0.0050\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0044 - accuracy: 0.0050\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 0.0050\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 0.0050\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.0050\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 0.0050\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.0050\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 0.0050\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0062 - accuracy: 0.0050\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0045 - accuracy: 0.0050\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.0050\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.0050\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.0050\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.0050\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.0050\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.0050\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 0.0050\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.0050\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.0050\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.0050\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 0.0050\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.0050\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.0050\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.0050\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.0050\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.0050\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.0050\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.0050\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.0050\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.0050\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 0.0050\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.0050\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.0050\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 9.3151e-04 - accuracy: 0.0050\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0036 - accuracy: 0.0050\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 7.1424e-04 - accuracy: 0.0050\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 6.7689e-04 - accuracy: 0.0050\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.0050\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 0.0050\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 8.9114e-04 - accuracy: 0.0050\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.0050\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 9.1086e-04 - accuracy: 0.0050\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.0050\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 9.1921e-04 - accuracy: 0.0050\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 9.9093e-04 - accuracy: 0.0050\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 6.4246e-04 - accuracy: 0.0050\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 6.5442e-04 - accuracy: 0.0050\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.0050\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.0050\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 6.7115e-04 - accuracy: 0.0050\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 8.8408e-04 - accuracy: 0.0050\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 6.1120e-04 - accuracy: 0.0050\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.0050\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 6.2285e-04 - accuracy: 0.0050\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 6.6043e-04 - accuracy: 0.0050\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 7.5823e-04 - accuracy: 0.0050\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 5.1469e-04 - accuracy: 0.0050\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 6.2967e-04 - accuracy: 0.0050\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 6.8545e-04 - accuracy: 0.0050\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 6.5029e-04 - accuracy: 0.0050\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 8.4160e-04 - accuracy: 0.0050\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.0050\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 5.2163e-04 - accuracy: 0.0050\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 5.5590e-04 - accuracy: 0.0050\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 7.0566e-04 - accuracy: 0.0050\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 4.3564e-04 - accuracy: 0.0050\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.0050\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 8.9886e-04 - accuracy: 0.0050\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 7.8099e-04 - accuracy: 0.0050\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdbe313ad10>"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "x_train = np.array([(x, x, x) for x in x_points])\n",
        "prediccion = model.predict(x=x_train)\n",
        "\n",
        "pyplot.plot(x_points, np.array([f(x, x, x) for x in x_points]))\n",
        "pyplot.plot(x_points, prediccion)\n",
        "\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "EibOarRxFwwO",
        "outputId": "26fe3419-112c-4377-9521-16e57239f666"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repetir con activación sigmoide. Extraer conclusiones."
      ],
      "metadata": {
        "id": "AhdEJfd1KJBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()                                          \n",
        "model.add(Dense(64, input_dim=3, activation='sigmoid'))         \n",
        "model.add(Dense(1))  \n",
        "\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=1)\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1), loss = 'MeanSquaredError', metrics=[\"accuracy\"])\n",
        "model.fit(training_data, target_data, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzbgyPTbKQBc",
        "outputId": "9edec776-12c6-4219-82c0-a83a55c25942"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 1s 1ms/step - loss: 1.3006 - accuracy: 0.0049\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.0050\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4142 - accuracy: 0.0047\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3755 - accuracy: 0.0041\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3258 - accuracy: 0.0039\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2605 - accuracy: 0.0039\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 0.0041\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.0044\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.1612 - accuracy: 0.0047\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.0047\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.1568 - accuracy: 0.0049\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.1368 - accuracy: 0.0049\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.1407 - accuracy: 0.0049\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.1340 - accuracy: 0.0050\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.1148 - accuracy: 0.0050\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.0050\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.1034 - accuracy: 0.0050\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0900 - accuracy: 0.0050\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0932 - accuracy: 0.0050\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0780 - accuracy: 0.0050\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0710 - accuracy: 0.0050\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0692 - accuracy: 0.0050\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0555 - accuracy: 0.0050\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0597 - accuracy: 0.0050\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0588 - accuracy: 0.0050\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0387 - accuracy: 0.0050\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0498 - accuracy: 0.0050\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0390 - accuracy: 0.0050\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0313 - accuracy: 0.0050\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0421 - accuracy: 0.0050\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0299 - accuracy: 0.0050\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0316 - accuracy: 0.0050\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0328 - accuracy: 0.0050\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0244 - accuracy: 0.0050\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0283 - accuracy: 0.0050\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0271 - accuracy: 0.0050\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 0.0050\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 0.0050\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0164 - accuracy: 0.0050\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 0.0050\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0259 - accuracy: 0.0050\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0174 - accuracy: 0.0050\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0185 - accuracy: 0.0050\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0149 - accuracy: 0.0050\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0234 - accuracy: 0.0050\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0131 - accuracy: 0.0050\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0188 - accuracy: 0.0049\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0158 - accuracy: 0.0050\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 0.0050\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 0.0050\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0128 - accuracy: 0.0050\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0117 - accuracy: 0.0050\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0089 - accuracy: 0.0050\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0124 - accuracy: 0.0050\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0140 - accuracy: 0.0050\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0099 - accuracy: 0.0050\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0058 - accuracy: 0.0050\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0181 - accuracy: 0.0050\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0082 - accuracy: 0.0050\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0076 - accuracy: 0.0050\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0103 - accuracy: 0.0050\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0109 - accuracy: 0.0050\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0096 - accuracy: 0.0050\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0099 - accuracy: 0.0050\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0071 - accuracy: 0.0050\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0071 - accuracy: 0.0050\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0057 - accuracy: 0.0050\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0083 - accuracy: 0.0050\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0094 - accuracy: 0.0050\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0103 - accuracy: 0.0050\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0073 - accuracy: 0.0050\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0050 - accuracy: 0.0050\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0072 - accuracy: 0.0050\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0045 - accuracy: 0.0050\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0053 - accuracy: 0.0050\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0130 - accuracy: 0.0050\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.0050\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0054 - accuracy: 0.0050\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0055 - accuracy: 0.0050\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0054 - accuracy: 0.0050\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.0050\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0149 - accuracy: 0.0050\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 0.0050\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 0.0050\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.0050\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.0050\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 0.0050\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0047 - accuracy: 0.0050\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.0050\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0081 - accuracy: 0.0050\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0047 - accuracy: 0.0050\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.0050\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0073 - accuracy: 0.0050\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.0050\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0040 - accuracy: 0.0050\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.0050\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0061 - accuracy: 0.0050\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0072 - accuracy: 0.0049\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.0050\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0035 - accuracy: 0.0050\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdbe3c3f690>"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "x_train = np.array([(x, x, x) for x in x_points])\n",
        "prediccion = model.predict(x=x_train)\n",
        "\n",
        "pyplot.plot(x_points, np.array([f(x, x, x) for x in x_points]))\n",
        "pyplot.plot(x_points, prediccion)\n",
        "\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "TsdSSv21KgSV",
        "outputId": "10a7636f-2bdf-460c-a884-f6e6717a02c8"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdbe3d94a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}