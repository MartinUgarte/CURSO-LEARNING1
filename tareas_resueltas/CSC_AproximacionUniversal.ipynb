{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "En toda esta sección se entrenarán redes neuronales de 1 sola capa oculta entrenando\n",
        "con gradiente descendente clásico. Se buscará apreciar las bondades de una red como\n",
        "aproximador universal (no nos importa por ahora la capacidad de generalización).\n",
        "\n"
      ],
      "metadata": {
        "id": "ElmQpqPwtxTC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Clasificación"
      ],
      "metadata": {
        "id": "PIxz8Ye9t0EB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Generar una base de datos de una XOR con todas las posibles combinaciones de\n",
        "±1 (4 casos). Asignar los labels correspondientes (1 si ambas entradas son iguales,\n",
        "0 si son diferentes)."
      ],
      "metadata": {
        "id": "dHxtsNi0t2FY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jEHtwpqDtiTN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Pongo -1 en vez de 0 para que la RELU pueda trabajar bien\n",
        "datos = [[-1, -1, 0],\n",
        "          [-1, 1, 1],\n",
        "          [1, -1, 1],\n",
        "         [1,1,0]]\n",
        "\n",
        "columnas = ['Bit 1', 'Bit 2', 'Output'] \n",
        "\n",
        "df = pd.DataFrame(datos, columns=columnas)\n",
        "df.head()\n",
        "\n",
        "training_data = df.loc[:,['Bit 1','Bit 2']]\n",
        "target_data = df.loc[:,'Output']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Entrenar una red neuronal con activación ReLU que alcance 100 % de accuracy. ¿Cuál es la mínima dimensión de la unidad oculta para lograr esto?"
      ],
      "metadata": {
        "id": "50gYj0mtwRLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "import tensorflow as tf\n",
        "\n",
        "# Creo la arquitectura de la red neuronal\n",
        "model = Sequential()                                          # Secuencial -> creo una serie de capas de neuronas secuenciales, una delante de otra.\n",
        "model.add(Dense(3, input_dim=2, activation='relu'))          # input_dim = 2 (defino la capa de entrada con 2 neuronas, BIT0 y BIT1 de XOR)\n",
        "model.add(Dense(1))                                           # La dimensión de la capa oculta es el primer parámetro\n",
        "                                                              # Por último agregamos una capa de salida (en este caso sin funcion de activacion xq estamos en clasificacion)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhDz6AkXyAfj",
        "outputId": "e8a8d6dd-1d7a-45dc-e19b-8bc3fa4a70a7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 3)                 9         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13\n",
            "Trainable params: 13\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=1)\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=5), loss = tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
        "model.fit(training_data, target_data, epochs=100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0hIGXDSzhnE",
        "outputId": "8efd4e07-5c8d-46da-f932-6e3eb83a0e4a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.8479 - accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6182 - accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4420 - accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3377 - accuracy: 0.7500\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2354 - accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1340 - accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0887 - accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0687 - accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0560 - accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0470 - accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0404 - accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0353 - accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0313 - accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0281 - accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0233 - accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0214 - accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0198 - accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0185 - accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0173 - accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0162 - accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0153 - accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0144 - accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0137 - accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0130 - accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0123 - accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0118 - accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0113 - accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0108 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0089 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0077 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0072 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0066 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2542203210>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La mínima dimensión de la unidad oculta para lograr esto es de 3 (fui probando)"
      ],
      "metadata": {
        "id": "STGL9GO92F7C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Repetir con activación sigmoide. Extraer conclusiones."
      ],
      "metadata": {
        "id": "L5_cL0Bs2Mcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creo la arquitectura de la red neuronal\n",
        "model = Sequential()                                          \n",
        "model.add(Dense(2, input_dim=2, activation='sigmoid'))         \n",
        "model.add(Dense(1))                     \n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCyWhGfw2QpB",
        "outputId": "c600128f-de8e-4dc9-9873-f0769b107dee"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 2)                 6         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9\n",
            "Trainable params: 9\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=1)\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=10), loss = tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
        "model.fit(training_data, target_data, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BwmsEwR3SKR",
        "outputId": "440a2954-5a44-4f07-aa4e-5ba97422f46f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 0.6441 - accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6292 - accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6133 - accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5975 - accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5830 - accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5706 - accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5620 - accuracy: 0.5000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5680 - accuracy: 0.7500\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6459 - accuracy: 0.5000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0166 - accuracy: 0.7500\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3194 - accuracy: 0.5000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4810 - accuracy: 0.7500\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7066 - accuracy: 0.5000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8554 - accuracy: 0.7500\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7200 - accuracy: 0.5000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9281 - accuracy: 0.7500\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5700 - accuracy: 0.5000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6269 - accuracy: 0.7500\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4091 - accuracy: 0.5000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3769 - accuracy: 0.7500\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2664 - accuracy: 0.5000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1794 - accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1262 - accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1042 - accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0932 - accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0845 - accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0774 - accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0714 - accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0663 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0618 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0580 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0546 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0516 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0489 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0464 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0442 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0422 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0404 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0387 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0372 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0358 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0345 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0332 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0321 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0310 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0300 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0291 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0282 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0274 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0266 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0245 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0239 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0233 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0227 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0222 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0216 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0211 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0207 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0202 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0198 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0194 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0190 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0186 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0182 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0179 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0175 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0172 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0169 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0166 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0163 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0160 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0158 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0155 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0152 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0150 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0147 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0145 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0143 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0141 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0139 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0137 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0135 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0133 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0131 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0129 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0127 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0125 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0124 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0122 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0120 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0119 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0117 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0114 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0113 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0112 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0110 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2541fea750>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede ver que utilizando la misma dimensión de unidades ocultas para lograr esto es de 2, usando 10 en learning rate"
      ],
      "metadata": {
        "id": "67Jt3cHp3f9X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Regresión"
      ],
      "metadata": {
        "id": "v1xL1G7U8uyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generar una base de datos de la función f(x, y, z) = sin(x) + cos(y) + z. Para ello\n",
        "barra una grilla de 20 puntos para cada coordenada (0 ≤ x < 2π, 0 ≤ y < 2π y\n",
        "0 ≤ z ≤ 1) y arme una base de datos con las 8000 combinaciones posibles."
      ],
      "metadata": {
        "id": "duyVatfK8x1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import itertools as it\n",
        "import numpy as np\n",
        "\n",
        "def f(x, y, z):\n",
        "  return math.sin(x) + math.cos(x) + z\n",
        "\n",
        "x_step = (2 * math.pi) / 20\n",
        "y_step = (2 * math.pi) / 20\n",
        "z_step = 1 / 20\n",
        "\n",
        "x_points, y_points, z_points = [], [], []\n",
        "for i in range(20): x_points.append(x_step * i)\n",
        "for i in range(20): y_points.append(y_step * i)\n",
        "for i in range(20): z_points.append(z_step * i)\n",
        "\n",
        "combinations = it.product(x_points, y_points)\n",
        "combinations = it.product(combinations, z_points)\n",
        "training_data = np.array([[x, y, z] for (x, y), z in combinations]) # Si quiero convertir un iterador a lista usar list(iterator)\n",
        "target_data = np.array([f(x, y, z) for x, y, z in training_data])"
      ],
      "metadata": {
        "id": "eBPPKrjC9rUz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenar una red neuronal con activación ReLU e indique el error cuadrático medio. Grafique f(x, x, x) y comparela con la salida del regresor barriendo x."
      ],
      "metadata": {
        "id": "Quh7UoPsBY_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()                                          \n",
        "model.add(Dense(64, input_dim=3, activation='relu'))         \n",
        "model.add(Dense(1))  \n",
        "\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=1)\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), loss = 'MeanSquaredError', metrics=[\"accuracy\"])\n",
        "model.fit(training_data, target_data, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uI0l6qYDBfoP",
        "outputId": "ec163fec-285a-4b8b-ec7a-449763bfe800"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6335 - accuracy: 0.0033\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.0034\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.0033\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.0031\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.0030\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.0031\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2856 - accuracy: 0.0035\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.0036\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2202 - accuracy: 0.0040\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.1933 - accuracy: 0.0039\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.1674 - accuracy: 0.0040\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.1436 - accuracy: 0.0041\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.1241 - accuracy: 0.0043\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.1080 - accuracy: 0.0044\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0912 - accuracy: 0.0045\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 0.0045\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0621 - accuracy: 0.0046\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0519 - accuracy: 0.0047\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0434 - accuracy: 0.0047\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.0050\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 0.0050\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.0050\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 0.0050\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.0050\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 0.0050\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 0.0050\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 0.0050\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0107 - accuracy: 0.0050\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0130 - accuracy: 0.0050\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 0.0050\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 0.0050\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.0050\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.0050\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0071 - accuracy: 0.0050\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0050\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0068 - accuracy: 0.0050\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.0050\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 0.0050\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.0050\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0050\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 0.0050\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 0.0050\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 0.0050\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 0.0050\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 0.0050\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 0.0050\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 0.0050\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 0.0050\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0047 - accuracy: 0.0050\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 0.0050\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.0050\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 0.0050\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 0.0050\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.0050\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 0.0050\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 0.0050\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 0.0050\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 0.0050\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.0050\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.0050\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.0050\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 0.0050\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 0.0050\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.0050\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.0050\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.0050\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 0.0050\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.0050\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.0050\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 0.0050\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 0.0050\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.0050\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 0.0050\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 0.0050\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.0050\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.0050\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.0050\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.0050\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.0050\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 0.0050\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 0.0050\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 0.0050\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.0050\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.0050\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.0050\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.0050\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.0050\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.0050\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.0050\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.0050\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.0050\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 0.0050\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.0050\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.0050\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.0050\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.0050\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.0050\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 0.0050\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.0050\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.0050\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2541f68d90>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "x_train = np.array([(x, x, x) for x in x_points])\n",
        "prediccion = model.predict(x=x_train)\n",
        "\n",
        "pyplot.plot(x_points, np.array([f(x, x, x) for x in x_points]))\n",
        "pyplot.plot(x_points, prediccion)\n",
        "\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "EibOarRxFwwO",
        "outputId": "b6f3ca92-6d90-4c34-ff0f-64b7dbb4e5d9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 76ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repetir con activación sigmoide. Extraer conclusiones."
      ],
      "metadata": {
        "id": "AhdEJfd1KJBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()                                          \n",
        "model.add(Dense(64, input_dim=3, activation='sigmoid'))         \n",
        "model.add(Dense(1))  \n",
        "\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=1)\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1), loss = 'MeanSquaredError', metrics=[\"accuracy\"])\n",
        "model.fit(training_data, target_data, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzbgyPTbKQBc",
        "outputId": "d50bb22e-4e76-4b0a-ddae-e282cf7b246c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 1s 1ms/step - loss: 1.6292 - accuracy: 0.0043\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4722 - accuracy: 0.0047\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4290 - accuracy: 0.0044\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.0039\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.0035\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3169 - accuracy: 0.0034\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.0037\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2048 - accuracy: 0.0036\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.1716 - accuracy: 0.0041\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.1661 - accuracy: 0.0045\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.0050\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.1553 - accuracy: 0.0049\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.0049\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.1241 - accuracy: 0.0050\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.1221 - accuracy: 0.0050\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.1129 - accuracy: 0.0050\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.1181 - accuracy: 0.0049\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.1050 - accuracy: 0.0049\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0945 - accuracy: 0.0050\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0832 - accuracy: 0.0049\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0889 - accuracy: 0.0050\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0746 - accuracy: 0.0050\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0713 - accuracy: 0.0050\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0731 - accuracy: 0.0049\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.0049\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0509 - accuracy: 0.0050\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.0050\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0495 - accuracy: 0.0050\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.0050\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0420 - accuracy: 0.0050\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.0050\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0410 - accuracy: 0.0050\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 0.0050\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0327 - accuracy: 0.0050\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 0.0050\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.0050\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 0.0050\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 0.0050\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0201 - accuracy: 0.0050\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0187 - accuracy: 0.0050\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0204 - accuracy: 0.0050\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.0050\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 0.0050\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 0.0050\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 0.0050\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 0.0050\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0164 - accuracy: 0.0050\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.0067 - accuracy: 0.0050\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 0.0050\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 0.0050\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 0.0050\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 0.0050\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 0.0050\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 0.0050\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 0.0050\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 0.0050\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0056 - accuracy: 0.0050\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 0.0050\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 0.0050\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 0.0050\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 0.0050\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 0.0050\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.0050\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 0.0050\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.0050\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 0.0050\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 0.0050\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 0.0050\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0083 - accuracy: 0.0050\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 0.0050\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 9.3015e-04 - accuracy: 0.0050\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 0.0050\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.0050\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.0050\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.0050\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.0050\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 0.0050\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 0.0050\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.0050\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.0050\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.0050\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.0050\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 0.0050\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.0050\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.0082 - accuracy: 0.0050\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 8.8675e-04 - accuracy: 0.0050\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 0.0050\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.0050\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.0050\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0031 - accuracy: 0.0050\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.0050\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 0.0050\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0010 - accuracy: 0.0050\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 5.7123e-04 - accuracy: 0.0050\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 0.0050\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 0.0050\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 8.4788e-04 - accuracy: 0.0050\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0020 - accuracy: 0.0050\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0019 - accuracy: 0.0050\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 9.6713e-04 - accuracy: 0.0050\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2547b6c950>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "x_train = np.array([(x, x, x) for x in x_points])\n",
        "prediccion = model.predict(x=x_train)\n",
        "\n",
        "pyplot.plot(x_points, np.array([f(x, x, x) for x in x_points]))\n",
        "pyplot.plot(x_points, prediccion)\n",
        "\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "TsdSSv21KgSV",
        "outputId": "3dc79889-1413-4274-cbec-b1886c05da3f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 41ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}